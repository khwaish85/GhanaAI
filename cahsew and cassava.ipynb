{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193c129c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-18T04:03:17.609765Z",
     "iopub.status.busy": "2025-07-18T04:03:17.609536Z",
     "iopub.status.idle": "2025-07-18T04:03:32.990687Z",
     "shell.execute_reply": "2025-07-18T04:03:32.990070Z"
    },
    "papermill": {
     "duration": 15.385095,
     "end_time": "2025-07-18T04:03:32.992013",
     "exception": false,
     "start_time": "2025-07-18T04:03:17.606918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 04:03:19.492604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752811399.711220      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752811399.789986      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable mixed precision training\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aae39d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T04:03:32.996648Z",
     "iopub.status.busy": "2025-07-18T04:03:32.996235Z",
     "iopub.status.idle": "2025-07-18T07:09:05.249957Z",
     "shell.execute_reply": "2025-07-18T07:09:05.249124Z"
    },
    "papermill": {
     "duration": 11132.624468,
     "end_time": "2025-07-18T07:09:05.618616",
     "exception": false,
     "start_time": "2025-07-18T04:03:32.994148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18910 images belonging to 5 classes.\n",
      "Found 6901 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752811426.085778      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752811460.691360      72 service.cc:148] XLA service 0x7a107c0031d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752811460.692272      72 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1752811464.091873      72 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/296\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 78ms/step - accuracy: 0.1875 - loss: 2.4978   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752811480.981640      72 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 2s/step - accuracy: 0.2523 - loss: 2.0535 - val_accuracy: 0.1942 - val_loss: 1.6900 - learning_rate: 3.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 1s/step - accuracy: 0.2873 - loss: 1.8554 - val_accuracy: 0.2439 - val_loss: 1.6694 - learning_rate: 3.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 994ms/step - accuracy: 0.3100 - loss: 1.7793 - val_accuracy: 0.2058 - val_loss: 1.6624 - learning_rate: 3.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 998ms/step - accuracy: 0.3113 - loss: 1.7447 - val_accuracy: 0.2656 - val_loss: 1.6433 - learning_rate: 3.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 996ms/step - accuracy: 0.3197 - loss: 1.7015 - val_accuracy: 0.2524 - val_loss: 1.6373 - learning_rate: 3.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 1s/step - accuracy: 0.3181 - loss: 1.6751 - val_accuracy: 0.2410 - val_loss: 1.6426 - learning_rate: 3.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.3402 - loss: 1.6429 - val_accuracy: 0.2852 - val_loss: 1.6267 - learning_rate: 3.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 997ms/step - accuracy: 0.3408 - loss: 1.6229 - val_accuracy: 0.2781 - val_loss: 1.6047 - learning_rate: 3.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 991ms/step - accuracy: 0.3293 - loss: 1.6236 - val_accuracy: 0.2707 - val_loss: 1.6202 - learning_rate: 3.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 1s/step - accuracy: 0.3401 - loss: 1.6018 - val_accuracy: 0.2632 - val_loss: 1.6001 - learning_rate: 3.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 1s/step - accuracy: 0.3472 - loss: 1.5897 - val_accuracy: 0.2521 - val_loss: 1.5983 - learning_rate: 3.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 989ms/step - accuracy: 0.3427 - loss: 1.5833 - val_accuracy: 0.2950 - val_loss: 1.5858 - learning_rate: 3.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 987ms/step - accuracy: 0.3487 - loss: 1.5749 - val_accuracy: 0.2466 - val_loss: 1.5906 - learning_rate: 3.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 985ms/step - accuracy: 0.3527 - loss: 1.5645 - val_accuracy: 0.2684 - val_loss: 1.6097 - learning_rate: 3.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 987ms/step - accuracy: 0.3603 - loss: 1.5544 - val_accuracy: 0.2708 - val_loss: 1.5801 - learning_rate: 3.0000e-04\n",
      "Epoch 16/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 1s/step - accuracy: 0.4578 - loss: 1.4198 - val_accuracy: 0.5072 - val_loss: 1.4799 - learning_rate: 1.0000e-04\n",
      "Epoch 17/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1s/step - accuracy: 0.6901 - loss: 1.0428 - val_accuracy: 0.7870 - val_loss: 0.8726 - learning_rate: 1.0000e-04\n",
      "Epoch 18/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 992ms/step - accuracy: 0.7775 - loss: 0.8972 - val_accuracy: 0.8473 - val_loss: 0.7625 - learning_rate: 1.0000e-04\n",
      "Epoch 19/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.8153 - loss: 0.8265 - val_accuracy: 0.8610 - val_loss: 0.7328 - learning_rate: 1.0000e-04\n",
      "Epoch 20/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 1s/step - accuracy: 0.8417 - loss: 0.7724 - val_accuracy: 0.8732 - val_loss: 0.7004 - learning_rate: 1.0000e-04\n",
      "Epoch 21/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 986ms/step - accuracy: 0.8629 - loss: 0.7309 - val_accuracy: 0.8786 - val_loss: 0.6892 - learning_rate: 1.0000e-04\n",
      "Epoch 22/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 996ms/step - accuracy: 0.8795 - loss: 0.7012 - val_accuracy: 0.8484 - val_loss: 0.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 23/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 994ms/step - accuracy: 0.8953 - loss: 0.6690 - val_accuracy: 0.8873 - val_loss: 0.6676 - learning_rate: 1.0000e-04\n",
      "Epoch 24/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 1s/step - accuracy: 0.8981 - loss: 0.6560 - val_accuracy: 0.8977 - val_loss: 0.6526 - learning_rate: 1.0000e-04\n",
      "Epoch 25/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 1s/step - accuracy: 0.9087 - loss: 0.6356 - val_accuracy: 0.8977 - val_loss: 0.6526 - learning_rate: 1.0000e-04\n",
      "Epoch 26/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.9137 - loss: 0.6191 - val_accuracy: 0.9210 - val_loss: 0.6058 - learning_rate: 5.0000e-05\n",
      "Epoch 27/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.9258 - loss: 0.6000 - val_accuracy: 0.9135 - val_loss: 0.6151 - learning_rate: 5.0000e-05\n",
      "Epoch 28/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.9302 - loss: 0.5880 - val_accuracy: 0.9091 - val_loss: 0.6254 - learning_rate: 5.0000e-05\n",
      "Epoch 29/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.9324 - loss: 0.5840 - val_accuracy: 0.9144 - val_loss: 0.6103 - learning_rate: 2.5000e-05\n",
      "Epoch 30/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.9338 - loss: 0.5810 - val_accuracy: 0.9119 - val_loss: 0.6200 - learning_rate: 5.0000e-05\n",
      "Epoch 31/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1s/step - accuracy: 0.9358 - loss: 0.5744 - val_accuracy: 0.9194 - val_loss: 0.5988 - learning_rate: 5.0000e-05\n",
      "Epoch 32/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.9344 - loss: 0.5735 - val_accuracy: 0.9200 - val_loss: 0.6031 - learning_rate: 5.0000e-05\n",
      "Epoch 33/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 994ms/step - accuracy: 0.9410 - loss: 0.5600 - val_accuracy: 0.9190 - val_loss: 0.5995 - learning_rate: 5.0000e-05\n",
      "Epoch 34/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.9397 - loss: 0.5600 - val_accuracy: 0.9220 - val_loss: 0.5926 - learning_rate: 5.0000e-05\n",
      "Epoch 35/35\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 999ms/step - accuracy: 0.9461 - loss: 0.5497 - val_accuracy: 0.9152 - val_loss: 0.6088 - learning_rate: 5.0000e-05\n",
      "\n",
      "✅ Cashew Test Accuracy: 92.20%\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 323ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " anthracnose       0.94      0.82      0.87      1838\n",
      "     gumosis       0.98      1.00      0.99       425\n",
      "     healthy       0.85      1.00      0.92      1336\n",
      "  leaf miner       0.92      0.90      0.91      1487\n",
      "    red rust       0.96      0.97      0.97      1815\n",
      "\n",
      "    accuracy                           0.92      6901\n",
      "   macro avg       0.93      0.94      0.93      6901\n",
      "weighted avg       0.92      0.92      0.92      6901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "base_path = \"/kaggle/input/dataset-for-crop-pest-and-disease-detection/Dataset for Crop Pest and Disease Detection\"\n",
    "train_dir = os.path.join(base_path, \"CCMT Dataset-Augmented/Cashew/train_set\")\n",
    "test_dir = os.path.join(base_path, \"CCMT Dataset-Augmented/Cashew/test_set\")\n",
    "\n",
    "# Parameters\n",
    "img_size = (224, 224)\n",
    "batch_size = 64\n",
    "epochs = 35\n",
    "\n",
    "# Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=35,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Loaders\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Model\n",
    "base_model = EfficientNetB3(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(768, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
    "x = Dropout(0.4)(x)  # Increased dropout\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax', dtype='float32')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze base model initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return 3e-4\n",
    "    elif epoch < 25:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        return 5e-5\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(3e-4),\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"cashew_best.weights.h5\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Phase 1: Frozen base model\n",
    "history1 = model.fit(\n",
    "    train_data,\n",
    "    epochs=15,\n",
    "    validation_data=test_data,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Phase 2: Unfreeze some layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_data,\n",
    "    initial_epoch=15,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_data,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "model.load_weights(\"cashew_best.weights.h5\")\n",
    "loss, acc = model.evaluate(test_data, verbose=0)\n",
    "print(f\"\\n✅ Cashew Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# Classification Report\n",
    "Y_pred = model.predict(test_data)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_data.classes, y_pred, target_names=list(test_data.class_indices.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c571ebc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:09:06.483812Z",
     "iopub.status.busy": "2025-07-18T07:09:06.483469Z",
     "iopub.status.idle": "2025-07-18T10:31:41.383048Z",
     "shell.execute_reply": "2025-07-18T10:31:41.382239Z"
    },
    "papermill": {
     "duration": 12155.3285,
     "end_time": "2025-07-18T10:31:41.384390",
     "exception": false,
     "start_time": "2025-07-18T07:09:06.055890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16971 images belonging to 5 classes.\n",
      "Found 7510 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 2s/step - accuracy: 0.5740 - loss: 0.1622 - val_accuracy: 0.1723 - val_loss: 0.1659 - learning_rate: 2.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 1s/step - accuracy: 0.8127 - loss: 0.1179 - val_accuracy: 0.4625 - val_loss: 0.1319 - learning_rate: 2.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1s/step - accuracy: 0.8676 - loss: 0.0955 - val_accuracy: 0.6555 - val_loss: 0.1008 - learning_rate: 2.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 1s/step - accuracy: 0.8830 - loss: 0.0766 - val_accuracy: 0.7075 - val_loss: 0.0784 - learning_rate: 2.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - accuracy: 0.8986 - loss: 0.0606 - val_accuracy: 0.6702 - val_loss: 0.0704 - learning_rate: 2.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1s/step - accuracy: 0.9113 - loss: 0.0463 - val_accuracy: 0.1928 - val_loss: nan - learning_rate: 2.0000e-04\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/reduce_lr_on_plateau.py:94: RuntimeWarning: invalid value encountered in less\n",
      "  self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - accuracy: 0.9162 - loss: 0.0350 - val_accuracy: 0.8373 - val_loss: 0.0333 - learning_rate: 2.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.9260 - loss: 0.0260 - val_accuracy: 0.7514 - val_loss: 0.0345 - learning_rate: 2.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1s/step - accuracy: 0.9270 - loss: 0.0193 - val_accuracy: 0.5586 - val_loss: 0.0464 - learning_rate: 2.0000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.9356 - loss: 0.0146 - val_accuracy: 0.4185 - val_loss: 0.0493 - learning_rate: 2.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1s/step - accuracy: 0.9240 - loss: 0.0126 - val_accuracy: 0.2591 - val_loss: 0.0628 - learning_rate: 2.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.9413 - loss: 0.0092 - val_accuracy: 0.8746 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.9534 - loss: 0.0076 - val_accuracy: 0.3370 - val_loss: 0.0903 - learning_rate: 1.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 1s/step - accuracy: 0.9536 - loss: 0.0067 - val_accuracy: 0.6111 - val_loss: 0.0479 - learning_rate: 1.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - accuracy: 0.9544 - loss: 0.0059 - val_accuracy: 0.8699 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 1s/step - accuracy: 0.9602 - loss: 0.0050 - val_accuracy: 0.8401 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 1s/step - accuracy: 0.9585 - loss: 0.0045 - val_accuracy: 0.8623 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 1s/step - accuracy: 0.9583 - loss: 0.0042 - val_accuracy: 0.5541 - val_loss: 0.0407 - learning_rate: 1.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 1s/step - accuracy: 0.9635 - loss: 0.0037 - val_accuracy: 0.7541 - val_loss: 0.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - accuracy: 0.9644 - loss: 0.0035 - val_accuracy: 0.2361 - val_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 1s/step - accuracy: 0.9662 - loss: 0.0032 - val_accuracy: 0.3491 - val_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.9718 - loss: 0.0029 - val_accuracy: 0.9381 - val_loss: 0.0057 - learning_rate: 5.0000e-05\n",
      "Epoch 23/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 1s/step - accuracy: 0.9735 - loss: 0.0024 - val_accuracy: 0.9250 - val_loss: 0.0062 - learning_rate: 5.0000e-05\n",
      "Epoch 24/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 1s/step - accuracy: 0.9756 - loss: 0.0023 - val_accuracy: 0.9104 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 25/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 1s/step - accuracy: 0.9742 - loss: 0.0023 - val_accuracy: 0.7126 - val_loss: 0.0244 - learning_rate: 5.0000e-05\n",
      "Epoch 26/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 1s/step - accuracy: 0.9749 - loss: 0.0022 - val_accuracy: 0.9495 - val_loss: 0.0048 - learning_rate: 5.0000e-05\n",
      "Epoch 27/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.9756 - loss: 0.0023 - val_accuracy: 0.9025 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 28/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.9766 - loss: 0.0019 - val_accuracy: 0.9362 - val_loss: 0.0060 - learning_rate: 5.0000e-05\n",
      "Epoch 29/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - accuracy: 0.9794 - loss: 0.0019 - val_accuracy: 0.9067 - val_loss: 0.0077 - learning_rate: 5.0000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 1s/step - accuracy: 0.9822 - loss: 0.0017 - val_accuracy: 0.8778 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.9822 - loss: 0.0016 - val_accuracy: 0.9514 - val_loss: 0.0045 - learning_rate: 2.5000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.9810 - loss: 0.0017 - val_accuracy: 0.9447 - val_loss: 0.0049 - learning_rate: 2.5000e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 1s/step - accuracy: 0.9864 - loss: 0.0014 - val_accuracy: 0.9578 - val_loss: 0.0045 - learning_rate: 2.5000e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.9824 - loss: 0.0015 - val_accuracy: 0.9574 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 1s/step - accuracy: 0.9853 - loss: 0.0014 - val_accuracy: 0.9538 - val_loss: 0.0047 - learning_rate: 2.5000e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 1s/step - accuracy: 0.9874 - loss: 0.0012 - val_accuracy: 0.9562 - val_loss: 0.0043 - learning_rate: 2.5000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.9838 - loss: 0.0013 - val_accuracy: 0.9566 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.9838 - loss: 0.0013 - val_accuracy: 0.9607 - val_loss: 0.0040 - learning_rate: 2.5000e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.9870 - loss: 0.0012 - val_accuracy: 0.9571 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.9850 - loss: 0.0013 - val_accuracy: 0.9403 - val_loss: 0.0057 - learning_rate: 2.5000e-05\n",
      "\n",
      "✅ Cassava Test Accuracy: 96.07%\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 368ms/step\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      green mite       0.95      0.96      0.95      1020\n",
      "bacterial blight       0.95      0.97      0.96      2623\n",
      "          mosaic       0.98      0.96      0.97      1200\n",
      "         healthy       0.99      0.97      0.98      1184\n",
      "      brown spot       0.95      0.94      0.94      1483\n",
      "\n",
      "        accuracy                           0.96      7510\n",
      "       macro avg       0.96      0.96      0.96      7510\n",
      "    weighted avg       0.96      0.96      0.96      7510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "base_path = \"/kaggle/input/dataset-for-crop-pest-and-disease-detection/Dataset for Crop Pest and Disease Detection\"\n",
    "train_dir = os.path.join(base_path, \"CCMT Dataset-Augmented/Cassava/train_set\")\n",
    "test_dir = os.path.join(base_path, \"CCMT Dataset-Augmented/Cassava/test_set\")\n",
    "\n",
    "# Handle duplicate classes\n",
    "valid_classes = [c for c in os.listdir(train_dir) if c in os.listdir(test_dir)]\n",
    "\n",
    "# Parameters\n",
    "img_size = (224, 224)\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "\n",
    "# Advanced Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=30,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Loaders\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=valid_classes\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=valid_classes\n",
    ")\n",
    "\n",
    "# Model with Stochastic Depth\n",
    "base_model = EfficientNetB3(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax', dtype='float32')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "# Class Weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_data.classes), y=train_data.classes)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Focal Loss\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        loss = alpha * tf.pow(1. - y_pred, gamma) * cross_entropy\n",
    "        return tf.reduce_mean(loss)\n",
    "    return loss_fn\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(2e-4),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"cassava_best.weights.h5\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6)\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_data,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "model.load_weights(\"cassava_best.weights.h5\")\n",
    "loss, acc = model.evaluate(test_data, verbose=0)\n",
    "print(f\"\\n✅ Cassava Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# Classification Report\n",
    "Y_pred = model.predict(test_data)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_data.classes, y_pred, target_names=list(test_data.class_indices.keys())))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7881725,
     "sourceId": 12489918,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23312.446743,
   "end_time": "2025-07-18T10:31:45.977779",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-18T04:03:13.531036",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
